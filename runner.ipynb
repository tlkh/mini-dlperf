{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0000:07:00.0,Tesla V100-DGXS-16GB': 'computeCapability: 7.0 coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s',\n",
       " '0000:08:00.0,Tesla V100-DGXS-16GB': 'computeCapability: 7.0 coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s',\n",
       " '0000:0e:00.0,Tesla V100-DGXS-16GB': 'computeCapability: 7.0 coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s',\n",
       " '0000:0f:00.0,Tesla V100-DGXS-16GB': 'computeCapability: 7.0 coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common import utils\n",
    "utils.get_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results format:\n",
    "\n",
    "`PASS, avg_fps, avg_sm, avg_mem, avg_pcie, pcie_gbps, avg_pwr, pwr_watts, avg_temp, max_vram, avg_nvlink, throttle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (Synthetic - High Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS,2045.2,93,35,14,2.3,73,221,52,9.5,12.1,['SwPowerCap']\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"hugecnn-10gb\"\n",
    "results = utils.run_command(\"python3 run_cnn.py --threads 38 --batch_size 80 --huge_cnn\")\n",
    "if results[-1].split(\",\")[0] == \"PASS\":\n",
    "    hugecnn_10gb = exp_name + results[-1]\n",
    "    print(hugecnn_10gb)\n",
    "else:\n",
    "    print(exp_name, \"FAIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (ResNet - Image Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No image augmentation (GPU limited)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"python3 run_cnn.py --threads 38 --batch_size 144\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"python3 run_cnn.py --threads 14 --batch_size 144\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image augmentation used (CPU limited)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"python3 run_cnn.py --img_aug  --threads 38 --batch_size 144\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"python3 run_cnn.py --img_aug  --threads 18 --batch_size 144\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"python3 run_cnn.py --img_aug  --threads 14 --batch_size 144\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer (Encoder-Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and cache the models locally first\n",
    "_ = utils.run_command(\"horovodrun -np 1 python3 run_t5.py --model t5-small --maxseqlen 128 --batch_size 1 --steps 1\")\n",
    "_ = utils.run_command(\"horovodrun -np 1 python3 run_t5.py --model t5-base --maxseqlen 128 --batch_size 1 --steps 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"horovodrun -np 4 python3 run_t5.py --model t5-small --xla --maxseqlen 512 --batch_size 16\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utils.run_command(\"horovodrun -np 4 python3 run_t5.py --model t5-base --xla --maxseqlen 512 --batch_size 4\")\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
